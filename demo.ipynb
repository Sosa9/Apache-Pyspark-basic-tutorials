{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic of Pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook covers below topics - \n",
    "\n",
    "## PART - 1\n",
    "#### - Pyspark Dataframe\n",
    "#### - Reading the dataset\n",
    "#### - Checking the datatypes (Schemas)\n",
    "#### - Selecting columns\n",
    "#### - Check describe\n",
    "#### - Adding columns\n",
    "#### - Dropping columns\n",
    "#### - Renaming columns\n",
    "\n",
    "Note: Set up an virtual environment first before starting the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ironman</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aquaman</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spiderman</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hulk</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name  Age\n",
       "0    Ironman   26\n",
       "1    Aquaman   25\n",
       "2  Spiderman   22\n",
       "3       Hulk   28"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"test.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting the Pyspark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Maheshmali:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1ff76269fd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+\n",
      "|      _c0|_c1|       _c2|\n",
      "+---------+---+----------+\n",
      "|     Name|Age|Experience|\n",
      "|  Ironman| 26|        10|\n",
      "|  Aquaman| 25|         2|\n",
      "|Spiderman| 22|         4|\n",
      "|     Hulk| 28|         6|\n",
      "+---------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.option('header','true').csv('test.csv',inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+\n",
      "|     Name|Age|Experience|\n",
      "+---------+---+----------+\n",
      "|  Ironman| 26|        10|\n",
      "|  Aquaman| 25|         2|\n",
      "|Spiderman| 22|         4|\n",
      "|     Hulk| 28|         6|\n",
      "+---------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the Schema (datatypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.csv('test.csv',header=True,inferSchema=True)\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting specific column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|     Name|Experience|\n",
      "+---------+----------+\n",
      "|  Ironman|        10|\n",
      "|  Aquaman|         2|\n",
      "|Spiderman|         4|\n",
      "|     Hulk|         6|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select('Name','Experience').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     Name|\n",
      "+---------+\n",
      "|  Ironman|\n",
      "|  Aquaman|\n",
      "|Spiderman|\n",
      "|     Hulk|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['Name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('Age', 'int'), ('Experience', 'int')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------------------+-----------------+\n",
      "|summary|     Name|               Age|       Experience|\n",
      "+-------+---------+------------------+-----------------+\n",
      "|  count|        4|                 4|                4|\n",
      "|   mean|     NULL|             25.25|              5.5|\n",
      "| stddev|     NULL|2.5000000000000004|3.415650255319866|\n",
      "|    min|  Aquaman|                22|                2|\n",
      "|    max|Spiderman|                28|               10|\n",
      "+-------+---------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.withColumn('Experience after 2 years',df_pyspark['Experience']+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+------------------------+\n",
      "|     Name|Age|Experience|Experience after 2 years|\n",
      "+---------+---+----------+------------------------+\n",
      "|  Ironman| 26|        10|                      12|\n",
      "|  Aquaman| 25|         2|                       4|\n",
      "|Spiderman| 22|         4|                       6|\n",
      "|     Hulk| 28|         6|                       8|\n",
      "+---------+---+----------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.drop('Experience after 2 years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+\n",
      "|     Name|Age|Experience|\n",
      "+---------+---+----------+\n",
      "|  Ironman| 26|        10|\n",
      "|  Aquaman| 25|         2|\n",
      "|Spiderman| 22|         4|\n",
      "|     Hulk| 28|         6|\n",
      "+---------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rename the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---+----------+\n",
      "| New Name|Age|Experience|\n",
      "+---------+---+----------+\n",
      "|  Ironman| 26|        10|\n",
      "|  Aquaman| 25|         2|\n",
      "|Spiderman| 22|         4|\n",
      "|     Hulk| 28|         6|\n",
      "+---------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.withColumnRenamed('name','New Name').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART - 2\n",
    "\n",
    "### - Dropping rows and columns\n",
    "### - Various parameter in dropping functionalities\n",
    "### - Handling missing values (mean, median, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+----------+------+\n",
      "|       name| age|experience|salary|\n",
      "+-----------+----+----------+------+\n",
      "|       hulk|  28|         8| 50000|\n",
      "|   superman|  38|        12| 80000|\n",
      "|wonderwoman|  25|         5| 48000|\n",
      "|       thor|NULL|      NULL| 40000|\n",
      "|       NULL|  23|         3| 28000|\n",
      "|       NULL|  29|      NULL|  NULL|\n",
      "+-----------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('test2.csv',header=True,inferSchema=True)  ## Using other sample csv file (test2.csv)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- experience: integer (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-----------------+------------------+------------------+\n",
      "|summary|       name|              age|        experience|            salary|\n",
      "+-------+-----------+-----------------+------------------+------------------+\n",
      "|  count|          4|                5|                 4|                 5|\n",
      "|   mean|       NULL|             28.6|               7.0|           49200.0|\n",
      "| stddev|       NULL|5.770615218501403|3.9157800414902435|19266.551326067674|\n",
      "|    min|       hulk|               23|                 3|             28000|\n",
      "|    max|wonderwoman|               38|                12|             80000|\n",
      "+-------+-----------+-----------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+------+\n",
      "| age|experience|salary|\n",
      "+----+----------+------+\n",
      "|  28|         8| 50000|\n",
      "|  38|        12| 80000|\n",
      "|  25|         5| 48000|\n",
      "|NULL|      NULL| 40000|\n",
      "|  23|         3| 28000|\n",
      "|  29|      NULL|  NULL|\n",
      "+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.drop('name').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treating Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+----------+------+\n",
      "|       name|age|experience|salary|\n",
      "+-----------+---+----------+------+\n",
      "|       hulk| 28|         8| 50000|\n",
      "|   superman| 38|        12| 80000|\n",
      "|wonderwoman| 25|         5| 48000|\n",
      "+-----------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## If inside drop nothing is passed, then it will drop all the rows that contains any null values.\n",
    "\n",
    "df.na.drop().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+----------+------+\n",
      "|       name| age|experience|salary|\n",
      "+-----------+----+----------+------+\n",
      "|       hulk|  28|         8| 50000|\n",
      "|   superman|  38|        12| 80000|\n",
      "|wonderwoman|  25|         5| 48000|\n",
      "|       thor|NULL|      NULL| 40000|\n",
      "|       NULL|  23|         3| 28000|\n",
      "|       NULL|  29|      NULL|  NULL|\n",
      "+-----------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## In drop different parameters can be passed. First considering 'how==all'. This will drop the rows that has all the values as null.\n",
    "\n",
    "df.na.drop(how=\"all\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+----------+------+\n",
      "|       name| age|experience|salary|\n",
      "+-----------+----+----------+------+\n",
      "|       hulk|  28|         8| 50000|\n",
      "|   superman|  38|        12| 80000|\n",
      "|wonderwoman|  25|         5| 48000|\n",
      "|       thor|NULL|      NULL| 40000|\n",
      "|       NULL|  23|         3| 28000|\n",
      "+-----------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## threshold --> the number denotes non-null values. \n",
    "\n",
    "df.na.drop(how='any',thresh=2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+----------+------+\n",
      "|       name|age|experience|salary|\n",
      "+-----------+---+----------+------+\n",
      "|       hulk| 28|         8| 50000|\n",
      "|   superman| 38|        12| 80000|\n",
      "|wonderwoman| 25|         5| 48000|\n",
      "|       NULL| 23|         3| 28000|\n",
      "|       NULL| 29|      NULL|  NULL|\n",
      "+-----------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Subset --> Can define a column in which whereever 'NA' is there will get removed.\n",
    "\n",
    "df.na.drop(how='any',subset=['age']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+----------+------+\n",
      "|          name| age|experience|salary|\n",
      "+--------------+----+----------+------+\n",
      "|          hulk|  28|         8| 50000|\n",
      "|      superman|  38|        12| 80000|\n",
      "|   wonderwoman|  25|         5| 48000|\n",
      "|          thor|NULL|      NULL| 40000|\n",
      "|Missing values|  23|         3| 28000|\n",
      "|Missing values|  29|      NULL|  NULL|\n",
      "+--------------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.fill('Missing values','name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+----------+------+\n",
      "|       name| age|experience|salary|\n",
      "+-----------+----+----------+------+\n",
      "|       hulk|  28|         8| 50000|\n",
      "|   superman|  38|        12| 80000|\n",
      "|wonderwoman|  25|         5| 48000|\n",
      "|       thor|NULL|      NULL| 40000|\n",
      "|       NULL|  23|         3| 28000|\n",
      "|       NULL|  29|      NULL|  NULL|\n",
      "+-----------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use an imputer function to replace the null values by mean values. Strategy can be changed accordingly.\n",
    "\n",
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(\n",
    "    inputCols = ['age','experience','salary'],\n",
    "    outputCols = [\"{}_imputed\".format(c) for c in ['age','experience','salary']]\n",
    ").setStrategy(\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+----------+------+-----------+------------------+--------------+\n",
      "|       name| age|experience|salary|age_imputed|experience_imputed|salary_imputed|\n",
      "+-----------+----+----------+------+-----------+------------------+--------------+\n",
      "|       hulk|  28|         8| 50000|         28|                 8|         50000|\n",
      "|   superman|  38|        12| 80000|         38|                12|         80000|\n",
      "|wonderwoman|  25|         5| 48000|         25|                 5|         48000|\n",
      "|       thor|NULL|      NULL| 40000|         28|                 7|         40000|\n",
      "|       NULL|  23|         3| 28000|         23|                 3|         28000|\n",
      "|       NULL|  29|      NULL|  NULL|         29|                 7|         49200|\n",
      "+-----------+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Add imputation cols to df\n",
    "\n",
    "imputer.fit(df).transform(df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+----------+------+\n",
      "|       name|age|experience|salary|\n",
      "+-----------+---+----------+------+\n",
      "|       hulk| 28|         8| 50000|\n",
      "|   superman| 38|        12| 80000|\n",
      "|wonderwoman| 25|         5| 48000|\n",
      "+-----------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = spark.read.csv('test3.csv',header=True,inferSchema=True)\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+----------+------+\n",
      "|       name|age|experience|salary|\n",
      "+-----------+---+----------+------+\n",
      "|       hulk| 28|         8| 50000|\n",
      "|wonderwoman| 25|         5| 48000|\n",
      "+-----------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Salary of people less than or equal to 50000\n",
    "\n",
    "df1.filter(\"salary<=50000\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+\n",
      "|       name|age|\n",
      "+-----------+---+\n",
      "|       hulk| 28|\n",
      "|wonderwoman| 25|\n",
      "+-----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Further filter of columns\n",
    "\n",
    "df1.filter(\"salary<=50000\").select(['name','age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+----------+------+\n",
      "|       name|age|experience|salary|\n",
      "+-----------+---+----------+------+\n",
      "|       hulk| 28|         8| 50000|\n",
      "|wonderwoman| 25|         5| 48000|\n",
      "+-----------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Apply multiple conditions (& -> and , | -> or)\n",
    "\n",
    "df1.filter((df1['salary']<=50000) | (df1['age'] < 27)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+------+\n",
      "|    name|age|experience|salary|\n",
      "+--------+---+----------+------+\n",
      "|superman| 38|        12| 80000|\n",
      "+--------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## App;y ~ -> not condition\n",
    "\n",
    "df1.filter(~(df1['salary']<=50000)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART - 4\n",
    "\n",
    "#### - Group by and Aggregate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+-------+\n",
      "|    name| departments| salary|\n",
      "+--------+------------+-------+\n",
      "|    hulk|     finance|50000.0|\n",
      "|   joker|          hr|30000.0|\n",
      "|    hulk|       legal|38000.0|\n",
      "|    loki|          hr|48000.0|\n",
      "|sherlock|data science|52000.0|\n",
      "|  batman|data science|60000.0|\n",
      "|    loki|     product|35000.0|\n",
      "+--------+------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.read.csv(\"test4.csv\",header=True,inferSchema=True)\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- departments: string (nullable = true)\n",
      " |-- salary: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------------+------------------+\n",
      "|summary|    name| departments|            salary|\n",
      "+-------+--------+------------+------------------+\n",
      "|  count|       7|           7|                 7|\n",
      "|   mean|    NULL|        NULL| 44714.28571428572|\n",
      "| stddev|    NULL|        NULL|10656.989658033293|\n",
      "|    min|  batman|data science|           30000.0|\n",
      "|    max|sherlock|     product|           60000.0|\n",
      "+-------+--------+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|    name|sum(salary)|\n",
      "+--------+-----------+\n",
      "|    loki|    83000.0|\n",
      "|   joker|    30000.0|\n",
      "|  batman|    60000.0|\n",
      "|sherlock|    52000.0|\n",
      "|    hulk|    88000.0|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## groupby name\n",
    "\n",
    "df2.groupBy('name').sum('salary').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "| departments|sum(salary)|\n",
      "+------------+-----------+\n",
      "|     finance|    50000.0|\n",
      "|       legal|    38000.0|\n",
      "|data science|   112000.0|\n",
      "|          hr|    78000.0|\n",
      "|     product|    35000.0|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## group by using department, checking the highest salary department wise\n",
    "\n",
    "df2.groupBy('departments').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+\n",
      "| departments|avg(salary)|\n",
      "+------------+-----------+\n",
      "|     finance|    50000.0|\n",
      "|       legal|    38000.0|\n",
      "|data science|    56000.0|\n",
      "|          hr|    39000.0|\n",
      "|     product|    35000.0|\n",
      "+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.groupBy('departments').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "| departments|count|\n",
      "+------------+-----+\n",
      "|     finance|    1|\n",
      "|       legal|    1|\n",
      "|data science|    2|\n",
      "|          hr|    2|\n",
      "|     product|    1|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## no. of people department wise\n",
    "\n",
    "df2.groupBy('departments').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(salary)|\n",
      "+-----------+\n",
      "|   313000.0|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Apply direct aggregate function\n",
    "\n",
    "df2.agg({'salary':'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|    name|max(salary)|\n",
      "+--------+-----------+\n",
      "|    loki|    48000.0|\n",
      "|   joker|    30000.0|\n",
      "|  batman|    60000.0|\n",
      "|sherlock|    52000.0|\n",
      "|    hulk|    50000.0|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.groupBy('name').max().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
